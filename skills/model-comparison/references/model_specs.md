# 模型规格参数参考

## 1. MiniMax M2.1

| 参数 | 值 |
|------|-----|
| 开发公司 | MiniMax |
| 上下文窗口 | 128K tokens |
| 主要特点 | 高性价比、中文优化 |
| API 定价 | 较低 |
| 适用场景 | 日常对话、文本处理、成本敏感 |

## 2. GLM-4.7

| 参数 | 值 |
|------|-----|
| 开发公司 | 智谱 AI (Zhipu AI) |
| 上下文窗口 | 128K tokens |
| 主要特点 | 中英文双语、企业级应用 |
| API 定价 | 中等 |
| 适用场景 | 企业应用、多任务处理、内容创作 |

## 3. DeepSeek Chat

| 参数 | 值 |
|------|-----|
| 开发公司 | DeepSeek |
| 上下文窗口 | 64K tokens |
| 主要特点 | 极低价格、代码能力强、数学推理优秀 |
| API 定价 | 极低（约为 GPT-4 的 1/10） |
| 适用场景 | 代码开发、技术分析、成本敏感项目 |

## 4. Qwen3 Coder Plus

| 参数 | 值 |
|------|-----|
| 开发公司 | 阿里云通义千问 |
| 上下文窗口 | 128K tokens |
| 主要特点 | 代码专项优化、长上下文、高性能 |
| API 定价 | 中等 |
| 适用场景 | 代码开发、复杂推理、长文档处理 |

## 5. Kimi K2 Thinking Turbo

| 参数 | 值 |
|------|-----|
| 开发公司 | 月之暗面 (Moonshot AI) |
| 上下文窗口 | 200K+ tokens |
| 主要特点 | 超长上下文、中文理解突出、深度思考 |
| API 定价 | 中等 |
| 适用场景 | 长文档理解、中文创作、深度分析 |

## 对比总结

| 模型 | 上下文 | 定价 | 最大优势 |
|------|--------|------|----------|
| MiniMax M2.1 | 128K | 低 | 性价比 |
| GLM-4.7 | 128K | 中 | 平衡性 |
| DeepSeek Chat | 64K | 极低 | 性价比+代码 |
| Qwen3 Coder Plus | 128K | 中 | 代码专项 |
| Kimi K2 | 200K+ | 中 | 超长上下文 |
